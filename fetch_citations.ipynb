{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcvJXfdvsbpH2vxyii+31e"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgZts9Mc6m7K",
        "outputId": "084af223-a7e9-48c6-e6cb-c76d05137da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "def fetch_data_from_csv(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Ensure the CSV has a 'Title' column\n",
        "    if 'Title' not in df.columns:\n",
        "        raise ValueError(\"The CSV file must contain a 'Title' column.\")\n",
        "\n",
        "    # Add a new column for the cited_by total\n",
        "    df['Cited By Total'] = None\n",
        "\n",
        "    # Iterate over the titles in the 'Title' column\n",
        "    for index, title in df['Title'].items():\n",
        "        total_cited_by = fetch_data(title)\n",
        "        df.at[index, 'Cited By Total'] = total_cited_by\n",
        "\n",
        "    # Save the updated DataFrame back to a CSV file\n",
        "    df.to_csv(file_path, index=False)\n",
        "\n",
        "def fetch_data(identifier):\n",
        "    params = {\n",
        "        \"engine\": \"google_scholar\",\n",
        "        \"q\": identifier,\n",
        "        \"api_key\": \"c2ddcabc7091dd635112964dac2d8fa85c686cb920292acf0f532cf9152c6466\"\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    organic_results = results.get(\"organic_results\", [])\n",
        "\n",
        "    for result in organic_results:\n",
        "        if \"inline_links\" in result and \"cited_by\" in result[\"inline_links\"]:\n",
        "            cited_by = result[\"inline_links\"][\"cited_by\"]\n",
        "            total_cited_by = cited_by.get('total', 0)\n",
        "            return total_cited_by\n",
        "\n",
        "    return 0  # Return 0 if no cited_by information is found\n",
        "\n",
        "\n",
        "# Example usage\n",
        "csv_file_path = \"/content/mental_health.csv\"  # Replace this with the path to your CSV file\n",
        "fetch_data_from_csv(csv_file_path)\n"
      ],
      "metadata": {
        "id": "wtYPCbdXDcVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "def fetch_data_from_csv(file_path):\n",
        "    # Read the CSV file, skipping the first 107 lines\n",
        "    df = pd.read_csv(file_path, skiprows=range(1, 105))\n",
        "\n",
        "    # Ensure the CSV has a 'Title' column\n",
        "    if 'Title' not in df.columns:\n",
        "        raise ValueError(\"The CSV file must contain a 'Title' column.\")\n",
        "\n",
        "    # Add a new column for the cited_by total\n",
        "    df['Cited By Total'] = None\n",
        "\n",
        "    # Iterate over the titles in the 'Title' column\n",
        "    for index, title in df['Title'].items():\n",
        "        total_cited_by = fetch_data(title)\n",
        "        df.at[index, 'Cited By Total'] = total_cited_by\n",
        "        print(f\"Processed paper '{title}' with {total_cited_by} citations.\")\n",
        "\n",
        "    # Save the updated DataFrame to a new CSV file\n",
        "    df.to_csv(\"mental_health_citations.csv\", index=False)\n",
        "\n",
        "def fetch_data(identifier):\n",
        "    params = {\n",
        "        \"engine\": \"google_scholar\",\n",
        "        \"q\": identifier,\n",
        "        \"api_key\": \"b38005e4cec34ec39311198e0f7683f23aab99c43673f687c6becaa2dc28800c\"\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    organic_results = results.get(\"organic_results\", [])\n",
        "\n",
        "    for result in organic_results:\n",
        "        if \"inline_links\" in result and \"cited_by\" in result[\"inline_links\"]:\n",
        "            cited_by = result[\"inline_links\"][\"cited_by\"]\n",
        "            total_cited_by = cited_by.get('total', 0)\n",
        "            return total_cited_by\n",
        "\n",
        "    return 0  # Return 0 if no cited_by information is found\n",
        "\n",
        "# Example usage\n",
        "csv_file_path = \"/content/mental_health.csv\"  # Replace this with the path to your CSV file\n",
        "fetch_data_from_csv(csv_file_path)\n"
      ],
      "metadata": {
        "id": "5zcILyS5-WIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9439553-b342-46d8-d8fc-48a34a78ca81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed paper 'DepressionOne@LT-EDI-ACL2022: Using Machine Learning with SMOTE and Random UnderSampling to Detect Signs of Depression on Social Media Text.' with 4 citations.\n",
            "Processed paper 'MUCS@Text-LT-EDI@ACL 2022: Detecting Sign of Depression from Social Media Text using Supervised Learning Approach' with 12 citations.\n",
            "Processed paper 'SSN@LT-EDI-ACL2022: Transfer Learning using BERT for Detecting Signs of Depression from Social Media Texts' with 6 citations.\n",
            "Processed paper 'Findings of the Shared Task on Detecting Signs of Depression from Social Media' with 32 citations.\n",
            "Processed paper 'DLRG@LT-EDI-ACL2022:Detecting signs of Depression from Social Media using XGBoost Method' with 7 citations.\n",
            "Processed paper 'IDIAP Submission@LT-EDI-ACL2022: Detecting Signs of Depression from Social Media Text' with 5 citations.\n",
            "Processed paper 'Stress Test Evaluation of Biomedical Word Embeddings' with 11 citations.\n",
            "Processed paper 'Comparing Selective Masking Methods for Depression Detection in Social Media' with 0 citations.\n",
            "Processed paper 'A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support' with 191 citations.\n",
            "Processed paper 'A Time-Aware Transformer Based Model for Suicide Ideation Detection on Social Media' with 91 citations.\n",
            "Processed paper 'IMFinE:An Integrated BERT-CNN-BiGRU Model for Mental Health Detection in Financial Context on Textual Data' with 3 citations.\n",
            "Processed paper 'Exploring Online Depression Forums via Text Mining: A Comparison of Reddit and a Curated Online Forum' with 22 citations.\n",
            "Processed paper 'Towards Preemptive Detection of Depression and Anxiety in Twitter' with 18 citations.\n",
            "Processed paper 'SMHD-GER: A Large-Scale Benchmark Dataset for Automatic Mental Health Detection from Social Media in German' with 1 citations.\n",
            "Processed paper 'Combining Psychological Theory with Language Models for Suicide Risk Detection' with 3 citations.\n",
            "Processed paper 'Boosting Distress Support Dialogue Responses with Motivational Interviewing Strategy' with 5 citations.\n",
            "Processed paper 'Coherent or Not? Stressing a Neural Language Model for Discourse Coherence in Multiple Languages' with 1 citations.\n",
            "Processed paper 'C2D2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health' with 1 citations.\n",
            "Processed paper 'Identifying Early Maladaptive Schemas from Mental Health Question Texts' with 0 citations.\n",
            "Processed paper 'Feature Attention Network: Interpretable Depression Detection from Social Media' with 57 citations.\n",
            "Processed paper 'Communicating Social Support in Online Self-help Groups for Anxiety and Depression: A Qualitative Discourse Analysis' with 4 citations.\n",
            "Processed paper 'Detecting Depression in Social Media using Fine-Grained Emotions' with 88 citations.\n",
            "Processed paper 'SNAP-BATNET: Cascading Author Profiling and Social Network Graphs for Suicide Ideation Detection on Social Media' with 73 citations.\n",
            "Processed paper 'On the State of Social Media Data for Mental Health Research' with 47 citations.\n",
            "Processed paper 'Determining a Person’s Suicide Risk by Voting on the Short-Term History of Tweets for the CLPsych 2021 Shared Task' with 14 citations.\n",
            "Processed paper 'Learning Models for Suicide Prediction from Social Media Posts' with 33 citations.\n",
            "Processed paper 'Suicide Risk Prediction by Tracking Self-Harm Aspects in Tweets: NUS-IDS at the CLPsych 2021 Shared Task' with 7 citations.\n",
            "Processed paper 'Team 9: A Comparison of Simple vs. Complex Models for Suicide Risk Assessment' with 4 citations.\n",
            "Processed paper 'Using Psychologically-Informed Priors for Suicide Prediction in the CLPsych 2021 Shared Task' with 10 citations.\n",
            "Processed paper 'Qualitative Analysis of Depression Models by Demographics' with 7 citations.\n",
            "Processed paper 'Towards the Development of Speech-Based Measures of Stress Response in Individuals' with 1 citations.\n",
            "Processed paper 'Towards Understanding the Role of Gender in Deploying Social Media-Based Mental Health Surveillance Models' with 8 citations.\n",
            "Processed paper 'Sifting French Tweets to Investigate the Impact of Covid-19 in Triggering Intense Anxiety' with 1 citations.\n",
            "Processed paper 'PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support' with 48 citations.\n",
            "Processed paper 'An Exploratory Analysis of the Relation between Offensive Language and Mental Health' with 21 citations.\n",
            "Processed paper 'Micromodels for Efficient, Explainable, and Reusable Systems: A Case Study on Mental Health' with 20 citations.\n",
            "Processed paper 'Girlbosses, The Red Pill, and the Anomie and Fatale of Gender Online: Analyzing Posts from r/SuicideWatch on Reddit' with 0 citations.\n",
            "Processed paper 'Temporal Tides of Emotional Resonance: A Novel Approach to Identify Mental Health on Social Media' with 0 citations.\n",
            "Processed paper 'Semantic Shifts in Mental Health-Related Concepts' with 1 citations.\n",
            "Processed paper 'Embodied Interaction in Mental Health Consultations: Some Observations on Grounding and Repair' with 0 citations.\n",
            "Processed paper 'AraDepSu: Detecting Depression and Suicidal Ideation in Arabic Tweets Using Transformers' with 5 citations.\n",
            "Processed paper 'A unified framework for cross-domain and cross-task learning of mental health conditions' with 2 citations.\n",
            "Processed paper 'PVG at WASSA 2021: A Multi-Input, Multi-Task, Transformer-Based Architecture for Empathy and Distress Prediction' with 9 citations.\n",
            "Processed paper 'EmpNa at WASSA 2021: A Lightweight Model for the Prediction of Empathy, Distress and Emotions from Reactions to News Stories' with 7 citations.\n",
            "Processed paper 'Event Detection for Suicide Understanding' with 8 citations.\n",
            "Processed paper 'Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers' with 2 citations.\n",
            "Processed paper 'Standardizing Distress Analysis: Emotion-Driven Distress Identification and Cause Extraction (DICE) in Multimodal Online Posts' with 0 citations.\n",
            "Processed paper 'Towards Interpretable Mental Health Analysis with Large Language Models' with 21 citations.\n",
            "Processed paper 'An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives' with 3 citations.\n",
            "Processed paper 'FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning' with 2 citations.\n",
            "Processed paper 'FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions' with 14 citations.\n",
            "Processed paper 'Task-Adaptive Tokenization: Enhancing Long-Form Text Generation Efficacy in Mental Health and Beyond' with 3 citations.\n",
            "Processed paper 'Semantic Similarity Models for Depression Severity Estimation' with 5 citations.\n",
            "Processed paper 'Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related Domains' with 3 citations.\n",
            "Processed paper 'DEPAC: a Corpus for Depression and Anxiety Detection from Speech' with 12 citations.\n",
            "Processed paper 'The ethical role of computational linguistics in digital psychological formulation and suicide prevention.' with 3 citations.\n",
            "Processed paper 'Explaining Models of Mental Health via Clinically Grounded Auxiliary Tasks' with 12 citations.\n",
            "Processed paper 'Then and Now: Quantifying the Longitudinal Validity of Self-Disclosed Depression Diagnoses' with 1 citations.\n",
            "Processed paper 'Tracking Mental Health Risks and Coping Strategies in Healthcare Workers’ Online Conversations Across the COVID-19 Pandemic' with 2 citations.\n",
            "Processed paper 'Comparing emotion feature extraction approaches for predicting depression and anxiety' with 21 citations.\n",
            "Processed paper 'Learning to Automate Follow-up Question Generation using Process Knowledge for Depression Triage on Reddit Posts' with 30 citations.\n",
            "Processed paper 'Approximate Nearest Neighbour Extraction Techniques and Neural Networks for Suicide Risk Prediction in the CLPsych 2022 Shared Task' with 6 citations.\n",
            "Processed paper 'Emotionally-Informed Models for Detecting Moments of Change and Suicide Risk Levels in Longitudinal Social Media Data' with 7 citations.\n",
            "Processed paper 'WWBP-SQT-lite: Multi-level Models and Difference Embeddings for Moments of Change Identification in Mental Health Forums' with 7 citations.\n",
            "Processed paper 'Approaching Stress and Performance in RSI: Proposal for Action to Take Back Control' with 3 citations.\n",
            "Processed paper 'Improving the Generalizability of Depression Detection by Leveraging Clinical Questionnaires' with 42 citations.\n",
            "Processed paper 'Acoustic Analysis of Native (L1) Bengali Speakers’ Phonological Realization of English Lexical Stress Contrast' with 0 citations.\n",
            "Processed paper 'The uncivil empathy: Investigating the relation between empathy and toxicity in online mental health support forums' with 0 citations.\n",
            "Processed paper 'Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts' with 17 citations.\n",
            "Processed paper 'SMHD: a Large-Scale Resource for Exploring Online Language Usage for Multiple Mental Health Conditions' with 150 citations.\n",
            "Processed paper 'Stress Test Evaluation for Natural Language Inference' with 348 citations.\n",
            "Processed paper 'How are you? Introducing stress-based text tailoring' with 4 citations.\n",
            "Processed paper 'Detection of Mental Health from Reddit via Deep Contextualized Representations' with 59 citations.\n",
            "Processed paper 'Evaluating Contextual Embeddings and their Extraction Layers for Depression Assessment' with 7 citations.\n",
            "Processed paper 'Empathy and Distress Prediction using Transformer Multi-output Regression and Emotion Analysis with an Ensemble of Supervised and Zero-Shot Learning Models' with 9 citations.\n",
            "Processed paper 'SURREY-CTS-NLP at WASSA2022: An Experiment of Discourse and Sentiment Analysis for the Prediction of Empathy, Distress and Emotion' with 7 citations.\n",
            "Processed paper 'Cluster Analysis of Online Mental Health Discourse using Topic-Infused Deep Contextualized Representations' with 2 citations.\n",
            "Processed paper 'MIAPARLE: Online training for the discrimination of stress contrasts' with 3 citations.\n",
            "Processed paper 'ScAN: Suicide Attempt and Ideation Events Dataset' with 6 citations.\n",
            "Processed paper 'Modeling Empathy and Distress in Reaction to News Stories' with 97 citations.\n",
            "Processed paper 'What type of happiness are you looking for? - A closer look at detecting mental health from language' with 25 citations.\n",
            "Processed paper 'A Linguistically-Informed Fusion Approach for Multimodal Depression Detection' with 34 citations.\n",
            "Processed paper 'Expert, Crowdsourced, and Machine Assessment of Suicide Risk via Online Postings' with 220 citations.\n",
            "Processed paper 'Hierarchical neural model with attention mechanisms for the classification of social media text related to mental health' with 81 citations.\n",
            "Processed paper 'Cross-cultural differences in language markers of depression online' with 57 citations.\n",
            "Processed paper 'Deep Learning for Depression Detection of Twitter Users' with 373 citations.\n",
            "Processed paper 'Can adult mental health be predicted by childhood future-self narratives? Insights from the CLPsych 2018 Shared Task' with 3 citations.\n",
            "Processed paper 'RSDD-Time: Temporal Annotation of Self-Reported Mental Health Diagnoses' with 39 citations.\n",
            "Processed paper 'Within and Between-Person Differences in Language Used Across Anxiety Support and Neutral Reddit Communities' with 28 citations.\n",
            "Processed paper 'Detecting Linguistic Traces of Depression in Topic-Restricted Text: Attending to Self-Stigmatized Depression with NLP' with 111 citations.\n",
            "Processed paper 'Deep learning for language understanding of mental health concepts derived from Cognitive Behavioural Therapy' with 20 citations.\n",
            "Processed paper 'Time Expressions in Mental Health Records for Symptom Onset Extraction' with 11 citations.\n",
            "Processed paper 'Identifying Depression on Reddit: The Effect of Training Data' with 96 citations.\n",
            "Processed paper 'What Makes You Stressed? Finding Reasons From Tweets' with 3 citations.\n",
            "Processed paper 'Trouble on the Road: Finding Reasons for Commuter Stress from Tweets' with 2 citations.\n",
            "Processed paper 'MANTIS at SMM4H’2022: Pre-Trained Language Models Meet a Suite of Psycholinguistic Features for the Detection of Self-Reported Chronic Stress' with 2 citations.\n",
            "Processed paper 'NCUEE-NLP@SMM4H’22: Classification of Self-reported Chronic Stress on Twitter Using Ensemble Pre-trained Transformer Models' with 3 citations.\n",
            "Processed paper 'The Best of Both Worlds: Combining Engineered Features with Transformers for Improved Mental Health Prediction from Reddit Posts' with 3 citations.\n",
            "Processed paper 'Multi-Task Learning for Depression Detection in Dialogs' with 10 citations.\n",
            "Processed paper 'The Influence of Context on the Learning of Metrical Stress Systems Using Finite-State Machines' with 2 citations.\n",
            "Processed paper 'Distinguishing between Dementia with Lewy bodies (DLB) and Alzheimer’s Disease (AD) using Mental Health Records: a Classification Approach' with 0 citations.\n",
            "Processed paper 'Hierarchical Attention Network for Explainable Depression Detection on Twitter Aided by Metaphor Concept Mappings' with 0 citations.\n",
            "Processed paper 'EM-PERSONA: EMotion-assisted Deep Neural Framework for PERSONAlity Subtyping from Suicide Notes' with 0 citations.\n",
            "Processed paper 'Detecting Suicide Risk in Online Counseling Services: A Study in a Low-Resource Language' with 0 citations.\n",
            "Processed paper 'EmoMent: An Emotion Annotated Mental Health Corpus from Two South Asian Countries' with 0 citations.\n",
            "Processed paper 'Assessing population-level symptoms of anxiety, depression, and suicide risk in real time using NLP applied to social media data' with 0 citations.\n",
            "Processed paper 'Detecting Depression in Thai Blog Posts: a Dataset and a Baseline' with 0 citations.\n",
            "Processed paper 'PHASE: Learning Emotional Phase-aware Representations for Suicide Ideation Detection on Social Media' with 0 citations.\n",
            "Processed paper 'Gender and Racial Fairness in Depression Research using Social Media' with 0 citations.\n",
            "Processed paper 'Data Augmentation for Mental Health Classification on Social Media' with 0 citations.\n",
            "Processed paper 'Stress Rules from Surface Forms: Experiments with Program Synthesis' with 0 citations.\n",
            "Processed paper 'Age-Specific Linguistic Features of Depression via Social Media' with 0 citations.\n",
            "Processed paper 'Empathetic Response Generation for Distress Support' with 0 citations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "def fetch_data_from_csv(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(file_path, skiprows=range(1, 105))\n",
        "\n",
        "    # Ensure the CSV has a 'Title' column\n",
        "    if 'Title' not in df.columns:\n",
        "        raise ValueError(\"The CSV file must contain a 'Title' column.\")\n",
        "\n",
        "    # Add a new column for the cited_by total\n",
        "    df['Cited By Total'] = None\n",
        "\n",
        "    # Iterate over the titles in the 'Title' column\n",
        "    for index, title in df['Title'].items():\n",
        "        total_cited_by = fetch_data(title)\n",
        "        df.at[index, 'Cited By Total'] = total_cited_by\n",
        "\n",
        "    # Save the updated DataFrame to a new CSV file\n",
        "    df.to_csv(\"mental_health_citations.csv\", index=False)\n",
        "\n",
        "def fetch_data(identifier):\n",
        "    params = {\n",
        "        \"engine\": \"google_scholar\",\n",
        "        \"q\": identifier,\n",
        "        \"api_key\": \"b38005e4cec34ec39311198e0f7683f23aab99c43673f687c6becaa2dc28800c\"\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    organic_results = results.get(\"organic_results\", [])\n",
        "\n",
        "    for result in organic_results:\n",
        "        if \"inline_links\" in result and \"cited_by\" in result[\"inline_links\"]:\n",
        "            cited_by = result[\"inline_links\"][\"cited_by\"]\n",
        "            total_cited_by = cited_by.get('total', 0)\n",
        "            return total_cited_by\n",
        "\n",
        "    return 0  # Return 0 if no cited_by information is found\n",
        "\n",
        "# Example usage\n",
        "csv_file_path = \"/content/mental_health.csv\"  # Replace this with the path to your CSV file\n",
        "\n",
        "# Start fetching data after line 108\n",
        "fetch_data_from_csv(csv_file_path)\n"
      ],
      "metadata": {
        "id": "3fhH0C6jATVl"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}